{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T00:16:10.753182Z",
     "start_time": "2024-06-12T00:16:10.748148Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:16:10.925103Z",
     "start_time": "2024-06-12T00:16:10.920584Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import AutoTokenizer, AutoModelForCausalLM,Trainer, TrainingArguments, DataCollatorForLanguageModeling",
   "id": "873f64e74b6fc81e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:16:11.439364Z",
     "start_time": "2024-06-12T00:16:11.435374Z"
    }
   },
   "cell_type": "code",
   "source": "from datasets import Dataset",
   "id": "94100e51c9186f4a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:25:55.054184Z",
     "start_time": "2024-06-12T00:25:54.873806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    LlamaTokenizer, \n",
    "    LlamaForCausalLM,\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, PeftModel,TaskType, get_peft_model\n",
    "#from bitsandbytes import quantize_model\n",
    "from trl import SFTTrainer"
   ],
   "id": "e1cf7a4f840bf81f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'quantize_model' from 'bitsandbytes' (E:\\modelo\\pythonProject\\venv\\Lib\\site-packages\\bitsandbytes\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 16\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      5\u001B[0m     AutoModelForCausalLM,\n\u001B[0;32m      6\u001B[0m     AutoTokenizer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m     LlamaForCausalLM,\n\u001B[0;32m     13\u001B[0m )\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpeft\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LoraConfig, PeftModel,TaskType, get_peft_model\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m quantize_model\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtrl\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SFTTrainer\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'quantize_model' from 'bitsandbytes' (E:\\modelo\\pythonProject\\venv\\Lib\\site-packages\\bitsandbytes\\__init__.py)"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:26:56.514660Z",
     "start_time": "2024-06-12T00:26:56.507642Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.version.cuda)",
   "id": "30eb0027ea6edab4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:27:07.108651Z",
     "start_time": "2024-06-12T00:27:07.103132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ],
   "id": "5752021855808d97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:35:31.964009Z",
     "start_time": "2024-06-12T00:35:31.410161Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('preguntas_respuesta')",
   "id": "1240741b4b115d05",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:35:32.023971Z",
     "start_time": "2024-06-12T00:35:31.967205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df['text'] = df['pregunta'] + df['respuesta']"
   ],
   "id": "c77b64c47379865e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:35:32.033133Z",
     "start_time": "2024-06-12T00:35:32.024976Z"
    }
   },
   "cell_type": "code",
   "source": "df = df[0:10]",
   "id": "f904d19f5a120b22",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:35:32.055337Z",
     "start_time": "2024-06-12T00:35:32.039656Z"
    }
   },
   "cell_type": "code",
   "source": "df=df.reset_index()",
   "id": "a08c389dfc5b86e0",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:35:32.224017Z",
     "start_time": "2024-06-12T00:35:32.213630Z"
    }
   },
   "cell_type": "code",
   "source": "nDf= df.loc[:,'text']",
   "id": "f9d6b1d028f19d4c",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:35:33.120644Z",
     "start_time": "2024-06-12T00:35:32.966938Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = Dataset.from_pandas(pd.DataFrame({'text': nDf}))",
   "id": "10bdfbecd403d40e",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:35:33.307187Z",
     "start_time": "2024-06-12T00:35:33.299359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(examples):\n",
    "    outputs = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    outputs[\"labels\"] = outputs[\"input_ids\"].copy()\n",
    "    return outputs\n"
   ],
   "id": "f4791dc98ac7eedd",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:35:33.643423Z",
     "start_time": "2024-06-12T00:35:33.539593Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fddab6ff6691b93",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:39:51.177403Z",
     "start_time": "2024-06-12T00:39:50.856708Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=['text'])",
   "id": "d4885413c45e18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd27e949f05e41b68247ffb833f54d5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:36:05.714915Z",
     "start_time": "2024-06-12T00:35:36.023876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"acalatrava/TinyLlama-1.1B-translate-en-es\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ],
   "id": "d246522e4a4029f0",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:25:46.755697Z",
     "start_time": "2024-06-12T00:25:45.691196Z"
    }
   },
   "cell_type": "code",
   "source": "#model = quantize_model(model, bits=4)",
   "id": "7681adfe6e80591a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quantize_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mquantize_model\u001B[49m(model, bits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'quantize_model' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=4,  # rango de la factorización\n",
    "    lora_alpha=32,  # multiplicador de la matriz de baja dimensión\n",
    "    lora_dropout=0.1,  # probabilidad de dropout\n",
    ")'''"
   ],
   "id": "2aa69abf41fc3b23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#model = get_peft_model(model, lora_config)",
   "id": "3e803ba4dcc7eb11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T00:39:55.091757Z",
     "start_time": "2024-06-12T00:39:55.060862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # No queremos enmascarado de lenguaje para GPT-2\n",
    ")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Directorio donde se guardarán los resultados\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,  # Número de épocas de entrenamiento\n",
    "    per_device_train_batch_size=2,  # Tamaño del lote de entrenamiento por dispositivo\n",
    "    save_steps=1,  # Pasos después de los cuales guardar el modelo\n",
    "    save_total_limit=2,\n",
    "    weight_decay=0.01,\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "# Definir el objeto Trainer y entrenar el modelo\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ],
   "id": "b7b30bfe91806481",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T01:02:15.192473Z",
     "start_time": "2024-06-12T00:39:55.644558Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "42d4c38b35fdf1dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 20:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=3.9157638549804688, metrics={'train_runtime': 1339.1379, 'train_samples_per_second': 0.007, 'train_steps_per_second': 0.004, 'total_flos': 7945055109120.0, 'train_loss': 3.9157638549804688, 'epoch': 1.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T01:06:37.139625Z",
     "start_time": "2024-06-12T01:05:15.943555Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model('llama')",
   "id": "d2163ebe29c36721",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2f1651688b9e81db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
